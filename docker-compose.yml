
version: "3.9"

services:
  jupyterhub:
    build:
      context: ./jupyterhub
      args:
        - JUPYTERHUB_VERSION=${JUPYTERHUB_VERSION:-4.0.2}
    image: jupyterhub
    ports:
      #- "80:8000"
      - "8000:8000"
      - "80:80"
      # This may be unnecessary as the proxy may handle port mapping for SSL
      - "443:443"
    container_name: jupyterhub-container
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
              - gpu
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      #- /shared:/shared
      #- jupyterhub_data:/srv/jupyterhub
      # Volumes for PAM authentication. Require restart to recognise new users
      #- /etc/passwd:/etc/passwd
      #- /etc/shadow:/etc/shadow
      #- /etc/group:/etc/group
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: all
      DOCKER_JUPYTER_IMAGE: cuda-dl-lab
      #DOCKER_JUPYTER_IMAGE: jupyterhub/singleuser
      DOCKER_NETWORK_NAME: ${COMPOSE_PROJECT_NAME}_default
      HUB_IP: jupyterhub
      #HUB_IP: "0.0.0.0"
      #AUTH_SERVER_ADDRESS: ${AUTH_SERVER_ADDRESS}
      ADMIN_USERS: ${ADMIN_USERS}
# WIP: These entries specify how to build each image with `docker-compose build` or
# `docker-compose build --no-cache`. Variables can be set in the `.env` file or with `--build-arg`.
# They also created containers which are made to exit with the `echo` command.
# TODO: Prevent containers being spawned at all (except jupyterhub-container).
# This can be achieved manually by specifying the service: `docker-compose up -d jupyterhub`
# TODO: Add docker-stacks-foundation layer
  cuda-stacks-foundation:
    build:
      context: https://github.com/jupyter/docker-stacks.git#main:images/docker-stacks-foundation
      dockerfile: Dockerfile
      args:
        - ROOT_CONTAINER=nvidia/cuda:${CUDA_VERSION:-11.8.0}-cudnn${CUDNN_VERSION:-8}-devel-${OS_BASE:-ubuntu22.04}
    image: cuda-stacks-foundation
    command: echo
  cuda-base-notebook:
    build:
      context: https://github.com/jupyter/docker-stacks.git#main:images/base-notebook
      dockerfile: Dockerfile
      args:
        - BASE_CONTAINER=cuda-stacks-foundation
    depends_on:
      - cuda-stacks-foundation
    image: cuda-base-notebook
    command: echo
  cuda-minimal-notebook:
    build:
      context: https://github.com/jupyter/docker-stacks.git#main:images/minimal-notebook
      dockerfile: Dockerfile
      args:
        - BASE_CONTAINER=cuda-base-notebook
    depends_on:
      - cuda-base-notebook
    image: cuda-minimal-notebook
    command: echo
  cuda-scipy-notebook:
    build:
      context: https://github.com/jupyter/docker-stacks.git#main:images/scipy-notebook
      dockerfile: Dockerfile
      args:
        - BASE_CONTAINER=cuda-minimal-notebook
    depends_on:
      - cuda-minimal-notebook
    image: cuda-scipy-notebook
    command: echo
  cuda-dl-lab:
    build:
      context: ./cuda-dl-lab
      args:
        - BASE_CONTAINER=cuda-scipy-notebook
        - CUDA_VERSION=${CUDA_VERSION:-11.8.0}
        - CUDNN_VERSION=${CUDNN_VERSION:-8}
        - OS_BASE=${OS_BASE:-ubuntu22.04}
    depends_on:
      - cuda-scipy-notebook
    image: cuda-dl-lab
    command: echo

# This service exists to test that the containers can mount GPUs
# Run with: `docker-compose up cuda-test`
  cuda-test:
    image: nvidia/cuda:${CUDA_VERSION:-11.8.0}-cudnn${CUDNN_VERSION:-8}-devel-${OS_BASE:-ubuntu22.04}
    command: nvidia-smi
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
              - gpu

volumes:
  jupyterhub_data:
